-- Create a stream from the transactions topic from the ActiveMQ connector
-- for transactions data. Since we're using Avro we can infer the schema
-- from the schema registry

create stream active with (KAFKA_TOPIC='from-activemq', VALUE_FORMAT='AVRO');

-- Extract transaction fields from the text subfield 

create stream activetext as 
 select MESSAGEID as MESSAGEID, 
        EXTRACTJSONFIELD(active.text, '$.transaction') as TRANSACTION,
        EXTRACTJSONFIELD(active.text, '$.amount') as AMOUNT,
        EXTRACTJSONFIELD(active.text, '$.timestamp') as TIMESTAMP,
        EXTRACTJSONFIELD(active.text, '$.user') as USERID 
 from active emit changes;

-- Extract typed transaction fields 

create stream activetransactions with (VALUE_FORMAT='AVRO') AS
 SELECT TRANSACTION as tx_type,
        SUBSTRING(AMOUNT,1,1) AS CURRENCY,
        CAST(SUBSTRING(AMOUNT,3,LEN(AMOUNT)-3) AS DECIMAL(9,2)) AS TX_AMOUNT,
	TIMESTAMP AS TX_TIMESTAMP,
        CAST ((USERID) AS INT) AS USERID
 FROM activetext where TIMESTAMP IS NOT NULL
 EMIT CHANGES; 
