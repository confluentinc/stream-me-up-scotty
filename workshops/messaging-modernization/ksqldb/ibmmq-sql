-- Create a stream from the topic sourced by the IBM MQ connector streaming
-- transactions data. Since it's Avro, we can infer the schema from the 
-- schema registry 

create stream ibmmq with (KAFKA_TOPIC='from-ibmmq', VALUE_FORMAT='AVRO');

-- Extract transaction subfields from the text field 

create stream ibmmqtext as 
 select EXTRACTJSONFIELD(ibmmq.text, '$.transaction') as TRANSACTION,
        EXTRACTJSONFIELD(ibmmq.text, '$.amount') as AMOUNT,
        EXTRACTJSONFIELD(ibmmq.text, '$.timestamp') as TIMESTAMP,
        EXTRACTJSONFIELD(ibmmq.text, '$.user') as USERID
 from ibmmq emit changes;

-- Extract typed transaction fields from the text stream 

create stream ibmmqtransactions with (VALUE_FORMAT='AVRO') AS
 SELECT TRANSACTION as tx_type,
        SUBSTRING(AMOUNT,1,1) AS CURRENCY,
        CAST(SUBSTRING(AMOUNT,3,LEN(AMOUNT)-3) AS DECIMAL(9,2)) AS TX_AMOUNT,
	TIMESTAMP AS TX_TIMESTAMP,
        CAST(USERID AS INT) AS USERID
 FROM ibmmqtext where TIMESTAMP IS NOT NULL
 EMIT CHANGES; 
